Tomer Levinboim (Notre Dame)
Multitask Word Alignment with Random-Walk Regularizers

3:00 pm - 4:00 pm
6th Floor Large Conference Room [689]

Suppose we translate a word from English to French and back. Should we get the original English word? That is, is translation invertible?
Alternatively, suppose we translate an English word e to Spanish and then from Spanish to French, obtaining a word f. 
Should e-f be a valid entry in an English-French dictionary? That is, is translation transitive?
Intuitively, if translation is done carefully, we expect to answer both these questions with "Yes, with high probability".
In this talk, I will discuss how to formulate our intuition about invertibility/transitivity with random-walks, using translation probability distributions.
I will then present two random-walk based regularization techniques that we recently used in a multitask word alignment setting:
(1) Model Invertibility Regularization (MIR) - a concave regularizer for bi-directional models which can be applied even without parallel data.
(2) Triangulation based Dirichlet prior - a method that capitalizes on parallel data with a pivot language, to construct and learn better translation priors.
This talk is based on joint work with Prof. David Chiang (ND) and Dr. Ashish Vaswani (ISI).

Bio: 
Tomer Levinboim is a PhD student at the University of Notre Dame, working with Prof. David Chiang on developing machine learning techniques for improving machine translation and NLP of low resource languages. 
He is generously hosted by Kevin Knight at USC/ISI.
